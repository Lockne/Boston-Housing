{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n",
      "shape: (506, 13)\n"
     ]
    }
   ],
   "source": [
    "bos = load_boston()\n",
    "print(bos.keys())\n",
    "print('shape:',bos.data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We load our data to a dataframe in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(bos.data)\n",
    "df.columns = bos.feature_names\n",
    "df['Price'] = bos.target\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unNormed = df.drop('Price', axis=1).to_numpy()\n",
    "Y_unNormed = df['Price'].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_rows(x):\n",
    "    x_norm = np.linalg.norm(x)\n",
    "    x = x/x_norm\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalise_rows(X_unNormed)\n",
    "Y = normalise_rows(Y_unNormed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 13)\n",
      "(152, 13)\n",
      "(354, 1)\n",
      "(152, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "Y_train = Y_train.reshape((354,1))\n",
    "Y_test = Y_test.reshape((152, 1))\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_input: torch.Size([354, 13])\n",
      "shape_targets: torch.Size([354, 1])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(X_train).float()\n",
    "targets = torch.from_numpy(Y_train).float()\n",
    "print('shape_input:',inputs.shape)\n",
    "print('shape_targets:', targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x7f780ab47c50>\n"
     ]
    }
   ],
   "source": [
    "train_ds = TensorDataset(inputs,targets)\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_d1 = DataLoader (train_ds, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.0230e-05, 1.5299e-03, 3.0368e-04, 0.0000e+00, 4.9492e-05, 5.2337e-04,\n",
      "         7.6494e-03, 1.5381e-04, 3.8247e-04, 2.0195e-02, 9.9443e-04, 2.9980e-02,\n",
      "         5.2781e-04],\n",
      "        [3.1188e-05, 0.0000e+00, 4.7426e-04, 7.6494e-05, 3.8783e-05, 4.7151e-04,\n",
      "         6.9839e-03, 2.3315e-04, 6.1195e-04, 2.3484e-02, 1.3310e-03, 3.0234e-02,\n",
      "         1.6416e-03],\n",
      "        [6.6275e-06, 3.4422e-03, 2.6314e-04, 0.0000e+00, 3.3428e-05, 5.4908e-04,\n",
      "         2.0118e-03, 4.9567e-04, 3.8247e-04, 3.0445e-02, 1.1627e-03, 2.9870e-02,\n",
      "         2.1954e-04],\n",
      "        [1.3692e-05, 0.0000e+00, 7.4123e-04, 0.0000e+00, 4.4749e-05, 4.3372e-04,\n",
      "         2.2030e-03, 2.1408e-04, 4.5897e-04, 2.9909e-02, 1.4687e-03, 3.0084e-02,\n",
      "         1.3463e-03],\n",
      "        [2.9232e-05, 0.0000e+00, 4.7426e-04, 0.0000e+00, 3.8553e-05, 6.1501e-04,\n",
      "         6.6168e-03, 2.4598e-04, 6.1195e-04, 2.3484e-02, 1.3310e-03, 2.9632e-02,\n",
      "         2.3943e-04]])\n",
      "tensor([[0.0550],\n",
      "        [0.0396],\n",
      "        [0.0665],\n",
      "        [0.0422],\n",
      "        [0.0687]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_d1:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(13,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1455,  0.2655, -0.1234, -0.1785, -0.0076,  0.1355,  0.2550,  0.0909,\n",
      "         -0.1266, -0.0304, -0.2361,  0.0246,  0.2114]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0026], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs.float())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function mse_loss at 0x7f7829485710>\n"
     ]
    }
   ],
   "source": [
    "loss_fn = F.mse_loss\n",
    "loss = loss_fn\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(num_epochs, model, loss_fn, opt, train_d1):\n",
    "    # repeat for number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # train with batches of data\n",
    "        for xb, yb in train_d1:\n",
    "            # 1. generate predictions\n",
    "            pred = model(xb)\n",
    "            # 2. calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            # 3. compute gradients\n",
    "            loss.backward()\n",
    "            # 4. update parameters using gradients\n",
    "            opt.step()\n",
    "            # 5. reset gradients to zero\n",
    "            opt.zero_grad()\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.0002\n",
      "Epoch [200/10000], Loss: 0.0001\n",
      "Epoch [300/10000], Loss: 0.0005\n",
      "Epoch [400/10000], Loss: 0.0003\n",
      "Epoch [500/10000], Loss: 0.0002\n",
      "Epoch [600/10000], Loss: 0.0001\n",
      "Epoch [700/10000], Loss: 0.0001\n",
      "Epoch [800/10000], Loss: 0.0000\n",
      "Epoch [900/10000], Loss: 0.0000\n",
      "Epoch [1000/10000], Loss: 0.0000\n",
      "Epoch [1100/10000], Loss: 0.0002\n",
      "Epoch [1200/10000], Loss: 0.0000\n",
      "Epoch [1300/10000], Loss: 0.0002\n",
      "Epoch [1400/10000], Loss: 0.0010\n",
      "Epoch [1500/10000], Loss: 0.0001\n",
      "Epoch [1600/10000], Loss: 0.0002\n",
      "Epoch [1700/10000], Loss: 0.0001\n",
      "Epoch [1800/10000], Loss: 0.0001\n",
      "Epoch [1900/10000], Loss: 0.0001\n",
      "Epoch [2000/10000], Loss: 0.0001\n",
      "Epoch [2100/10000], Loss: 0.0009\n",
      "Epoch [2200/10000], Loss: 0.0000\n",
      "Epoch [2300/10000], Loss: 0.0003\n",
      "Epoch [2400/10000], Loss: 0.0001\n",
      "Epoch [2500/10000], Loss: 0.0001\n",
      "Epoch [2600/10000], Loss: 0.0001\n",
      "Epoch [2700/10000], Loss: 0.0011\n",
      "Epoch [2800/10000], Loss: 0.0004\n",
      "Epoch [2900/10000], Loss: 0.0000\n",
      "Epoch [3000/10000], Loss: 0.0006\n",
      "Epoch [3100/10000], Loss: 0.0003\n",
      "Epoch [3200/10000], Loss: 0.0003\n",
      "Epoch [3300/10000], Loss: 0.0001\n",
      "Epoch [3400/10000], Loss: 0.0005\n",
      "Epoch [3500/10000], Loss: 0.0002\n",
      "Epoch [3600/10000], Loss: 0.0003\n",
      "Epoch [3700/10000], Loss: 0.0002\n",
      "Epoch [3800/10000], Loss: 0.0001\n",
      "Epoch [3900/10000], Loss: 0.0004\n",
      "Epoch [4000/10000], Loss: 0.0002\n",
      "Epoch [4100/10000], Loss: 0.0001\n",
      "Epoch [4200/10000], Loss: 0.0001\n",
      "Epoch [4300/10000], Loss: 0.0007\n",
      "Epoch [4400/10000], Loss: 0.0004\n",
      "Epoch [4500/10000], Loss: 0.0000\n",
      "Epoch [4600/10000], Loss: 0.0003\n",
      "Epoch [4700/10000], Loss: 0.0002\n",
      "Epoch [4800/10000], Loss: 0.0000\n",
      "Epoch [4900/10000], Loss: 0.0002\n",
      "Epoch [5000/10000], Loss: 0.0001\n",
      "Epoch [5100/10000], Loss: 0.0003\n",
      "Epoch [5200/10000], Loss: 0.0000\n",
      "Epoch [5300/10000], Loss: 0.0002\n",
      "Epoch [5400/10000], Loss: 0.0008\n",
      "Epoch [5500/10000], Loss: 0.0001\n",
      "Epoch [5600/10000], Loss: 0.0002\n",
      "Epoch [5700/10000], Loss: 0.0001\n",
      "Epoch [5800/10000], Loss: 0.0002\n",
      "Epoch [5900/10000], Loss: 0.0008\n",
      "Epoch [6000/10000], Loss: 0.0001\n",
      "Epoch [6100/10000], Loss: 0.0002\n",
      "Epoch [6200/10000], Loss: 0.0000\n",
      "Epoch [6300/10000], Loss: 0.0007\n",
      "Epoch [6400/10000], Loss: 0.0004\n",
      "Epoch [6500/10000], Loss: 0.0001\n",
      "Epoch [6600/10000], Loss: 0.0002\n",
      "Epoch [6700/10000], Loss: 0.0002\n",
      "Epoch [6800/10000], Loss: 0.0002\n",
      "Epoch [6900/10000], Loss: 0.0002\n",
      "Epoch [7000/10000], Loss: 0.0001\n",
      "Epoch [7100/10000], Loss: 0.0007\n",
      "Epoch [7200/10000], Loss: 0.0001\n",
      "Epoch [7300/10000], Loss: 0.0000\n",
      "Epoch [7400/10000], Loss: 0.0005\n",
      "Epoch [7500/10000], Loss: 0.0002\n",
      "Epoch [7600/10000], Loss: 0.0009\n",
      "Epoch [7700/10000], Loss: 0.0000\n",
      "Epoch [7800/10000], Loss: 0.0005\n",
      "Epoch [7900/10000], Loss: 0.0002\n",
      "Epoch [8000/10000], Loss: 0.0001\n",
      "Epoch [8100/10000], Loss: 0.0002\n",
      "Epoch [8200/10000], Loss: 0.0000\n",
      "Epoch [8300/10000], Loss: 0.0003\n",
      "Epoch [8400/10000], Loss: 0.0008\n",
      "Epoch [8500/10000], Loss: 0.0000\n",
      "Epoch [8600/10000], Loss: 0.0001\n",
      "Epoch [8700/10000], Loss: 0.0002\n",
      "Epoch [8800/10000], Loss: 0.0003\n",
      "Epoch [8900/10000], Loss: 0.0001\n",
      "Epoch [9000/10000], Loss: 0.0000\n",
      "Epoch [9100/10000], Loss: 0.0003\n",
      "Epoch [9200/10000], Loss: 0.0003\n",
      "Epoch [9300/10000], Loss: 0.0002\n",
      "Epoch [9400/10000], Loss: 0.0001\n",
      "Epoch [9500/10000], Loss: 0.0001\n",
      "Epoch [9600/10000], Loss: 0.0001\n",
      "Epoch [9700/10000], Loss: 0.0002\n",
      "Epoch [9800/10000], Loss: 0.0002\n",
      "Epoch [9900/10000], Loss: 0.0002\n",
      "Epoch [10000/10000], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "fit(10000, model, loss_fn, opt, train_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0421],\n",
       "        [0.0419],\n",
       "        [0.0417],\n",
       "        [0.0412],\n",
       "        [0.0412],\n",
       "        [0.0413],\n",
       "        [0.0418],\n",
       "        [0.0425],\n",
       "        [0.0425],\n",
       "        [0.0427],\n",
       "        [0.0416],\n",
       "        [0.0418],\n",
       "        [0.0426],\n",
       "        [0.0425],\n",
       "        [0.0431],\n",
       "        [0.0417],\n",
       "        [0.0425],\n",
       "        [0.0431],\n",
       "        [0.0413],\n",
       "        [0.0425],\n",
       "        [0.0416],\n",
       "        [0.0423],\n",
       "        [0.0412],\n",
       "        [0.0418],\n",
       "        [0.0421],\n",
       "        [0.0414],\n",
       "        [0.0420],\n",
       "        [0.0425],\n",
       "        [0.0427],\n",
       "        [0.0421],\n",
       "        [0.0419],\n",
       "        [0.0417],\n",
       "        [0.0422],\n",
       "        [0.0425],\n",
       "        [0.0408],\n",
       "        [0.0426],\n",
       "        [0.0414],\n",
       "        [0.0414],\n",
       "        [0.0414],\n",
       "        [0.0422],\n",
       "        [0.0420],\n",
       "        [0.0417],\n",
       "        [0.0421],\n",
       "        [0.0424],\n",
       "        [0.0415],\n",
       "        [0.0424],\n",
       "        [0.0416],\n",
       "        [0.0423],\n",
       "        [0.0424],\n",
       "        [0.0421],\n",
       "        [0.0423],\n",
       "        [0.0424],\n",
       "        [0.0422],\n",
       "        [0.0421],\n",
       "        [0.0420],\n",
       "        [0.0422],\n",
       "        [0.0428],\n",
       "        [0.0422],\n",
       "        [0.0406],\n",
       "        [0.0417],\n",
       "        [0.0408],\n",
       "        [0.0413],\n",
       "        [0.0418],\n",
       "        [0.0432],\n",
       "        [0.0418],\n",
       "        [0.0404],\n",
       "        [0.0415],\n",
       "        [0.0419],\n",
       "        [0.0410],\n",
       "        [0.0431],\n",
       "        [0.0421],\n",
       "        [0.0421],\n",
       "        [0.0416],\n",
       "        [0.0420],\n",
       "        [0.0431],\n",
       "        [0.0423],\n",
       "        [0.0414],\n",
       "        [0.0427],\n",
       "        [0.0425],\n",
       "        [0.0420],\n",
       "        [0.0422],\n",
       "        [0.0421],\n",
       "        [0.0421],\n",
       "        [0.0431],\n",
       "        [0.0424],\n",
       "        [0.0411],\n",
       "        [0.0425],\n",
       "        [0.0426],\n",
       "        [0.0423],\n",
       "        [0.0424],\n",
       "        [0.0422],\n",
       "        [0.0418],\n",
       "        [0.0429],\n",
       "        [0.0421],\n",
       "        [0.0431],\n",
       "        [0.0417],\n",
       "        [0.0423],\n",
       "        [0.0427],\n",
       "        [0.0414],\n",
       "        [0.0423],\n",
       "        [0.0418],\n",
       "        [0.0416],\n",
       "        [0.0423],\n",
       "        [0.0418],\n",
       "        [0.0433],\n",
       "        [0.0418],\n",
       "        [0.0421],\n",
       "        [0.0417],\n",
       "        [0.0427],\n",
       "        [0.0408],\n",
       "        [0.0423],\n",
       "        [0.0430],\n",
       "        [0.0417],\n",
       "        [0.0423],\n",
       "        [0.0427],\n",
       "        [0.0422],\n",
       "        [0.0425],\n",
       "        [0.0423],\n",
       "        [0.0436],\n",
       "        [0.0428],\n",
       "        [0.0429],\n",
       "        [0.0427],\n",
       "        [0.0418],\n",
       "        [0.0405],\n",
       "        [0.0422],\n",
       "        [0.0427],\n",
       "        [0.0413],\n",
       "        [0.0414],\n",
       "        [0.0432],\n",
       "        [0.0427],\n",
       "        [0.0428],\n",
       "        [0.0423],\n",
       "        [0.0413],\n",
       "        [0.0426],\n",
       "        [0.0423],\n",
       "        [0.0404],\n",
       "        [0.0430],\n",
       "        [0.0422],\n",
       "        [0.0425],\n",
       "        [0.0410],\n",
       "        [0.0413],\n",
       "        [0.0421],\n",
       "        [0.0417],\n",
       "        [0.0414],\n",
       "        [0.0412],\n",
       "        [0.0424],\n",
       "        [0.0422],\n",
       "        [0.0415],\n",
       "        [0.0418],\n",
       "        [0.0416],\n",
       "        [0.0407],\n",
       "        [0.0406],\n",
       "        [0.0420],\n",
       "        [0.0425],\n",
       "        [0.0423],\n",
       "        [0.0422],\n",
       "        [0.0432],\n",
       "        [0.0433],\n",
       "        [0.0421],\n",
       "        [0.0422],\n",
       "        [0.0423],\n",
       "        [0.0422],\n",
       "        [0.0422],\n",
       "        [0.0419],\n",
       "        [0.0421],\n",
       "        [0.0423],\n",
       "        [0.0427],\n",
       "        [0.0413],\n",
       "        [0.0422],\n",
       "        [0.0422],\n",
       "        [0.0416],\n",
       "        [0.0422],\n",
       "        [0.0412],\n",
       "        [0.0418],\n",
       "        [0.0412],\n",
       "        [0.0427],\n",
       "        [0.0434],\n",
       "        [0.0420],\n",
       "        [0.0425],\n",
       "        [0.0421],\n",
       "        [0.0411],\n",
       "        [0.0424],\n",
       "        [0.0419],\n",
       "        [0.0422],\n",
       "        [0.0426],\n",
       "        [0.0422],\n",
       "        [0.0427],\n",
       "        [0.0418],\n",
       "        [0.0422],\n",
       "        [0.0427],\n",
       "        [0.0419],\n",
       "        [0.0426],\n",
       "        [0.0426],\n",
       "        [0.0417],\n",
       "        [0.0419],\n",
       "        [0.0423],\n",
       "        [0.0410],\n",
       "        [0.0418],\n",
       "        [0.0414],\n",
       "        [0.0419],\n",
       "        [0.0423],\n",
       "        [0.0431],\n",
       "        [0.0410],\n",
       "        [0.0421],\n",
       "        [0.0434],\n",
       "        [0.0417],\n",
       "        [0.0421],\n",
       "        [0.0424],\n",
       "        [0.0411],\n",
       "        [0.0414],\n",
       "        [0.0402],\n",
       "        [0.0424],\n",
       "        [0.0416],\n",
       "        [0.0430],\n",
       "        [0.0416],\n",
       "        [0.0432],\n",
       "        [0.0428],\n",
       "        [0.0423],\n",
       "        [0.0427],\n",
       "        [0.0417],\n",
       "        [0.0428],\n",
       "        [0.0416],\n",
       "        [0.0424],\n",
       "        [0.0416],\n",
       "        [0.0421],\n",
       "        [0.0430],\n",
       "        [0.0428],\n",
       "        [0.0423],\n",
       "        [0.0411],\n",
       "        [0.0424],\n",
       "        [0.0426],\n",
       "        [0.0423],\n",
       "        [0.0423],\n",
       "        [0.0411],\n",
       "        [0.0433],\n",
       "        [0.0413],\n",
       "        [0.0409],\n",
       "        [0.0426],\n",
       "        [0.0431],\n",
       "        [0.0424],\n",
       "        [0.0418],\n",
       "        [0.0427],\n",
       "        [0.0419],\n",
       "        [0.0405],\n",
       "        [0.0416],\n",
       "        [0.0419],\n",
       "        [0.0421],\n",
       "        [0.0417],\n",
       "        [0.0425],\n",
       "        [0.0421],\n",
       "        [0.0422],\n",
       "        [0.0424],\n",
       "        [0.0419],\n",
       "        [0.0414],\n",
       "        [0.0414],\n",
       "        [0.0412],\n",
       "        [0.0414],\n",
       "        [0.0410],\n",
       "        [0.0417],\n",
       "        [0.0424],\n",
       "        [0.0426],\n",
       "        [0.0432],\n",
       "        [0.0421],\n",
       "        [0.0411],\n",
       "        [0.0425],\n",
       "        [0.0419],\n",
       "        [0.0419],\n",
       "        [0.0423],\n",
       "        [0.0433],\n",
       "        [0.0425],\n",
       "        [0.0418],\n",
       "        [0.0418],\n",
       "        [0.0425],\n",
       "        [0.0415],\n",
       "        [0.0415],\n",
       "        [0.0423],\n",
       "        [0.0407],\n",
       "        [0.0420],\n",
       "        [0.0413],\n",
       "        [0.0425],\n",
       "        [0.0409],\n",
       "        [0.0433],\n",
       "        [0.0409],\n",
       "        [0.0413],\n",
       "        [0.0424],\n",
       "        [0.0419],\n",
       "        [0.0415],\n",
       "        [0.0418],\n",
       "        [0.0417],\n",
       "        [0.0432],\n",
       "        [0.0428],\n",
       "        [0.0419],\n",
       "        [0.0423],\n",
       "        [0.0426],\n",
       "        [0.0419],\n",
       "        [0.0424],\n",
       "        [0.0423],\n",
       "        [0.0410],\n",
       "        [0.0418],\n",
       "        [0.0421],\n",
       "        [0.0430],\n",
       "        [0.0413],\n",
       "        [0.0420],\n",
       "        [0.0415],\n",
       "        [0.0430],\n",
       "        [0.0414],\n",
       "        [0.0424],\n",
       "        [0.0414],\n",
       "        [0.0422],\n",
       "        [0.0411],\n",
       "        [0.0423],\n",
       "        [0.0423],\n",
       "        [0.0414],\n",
       "        [0.0423],\n",
       "        [0.0423],\n",
       "        [0.0418],\n",
       "        [0.0432],\n",
       "        [0.0423],\n",
       "        [0.0420],\n",
       "        [0.0412],\n",
       "        [0.0425],\n",
       "        [0.0423],\n",
       "        [0.0414],\n",
       "        [0.0421],\n",
       "        [0.0426],\n",
       "        [0.0418],\n",
       "        [0.0421],\n",
       "        [0.0420],\n",
       "        [0.0412],\n",
       "        [0.0416],\n",
       "        [0.0429],\n",
       "        [0.0430],\n",
       "        [0.0423],\n",
       "        [0.0425],\n",
       "        [0.0423],\n",
       "        [0.0424],\n",
       "        [0.0413],\n",
       "        [0.0421],\n",
       "        [0.0413],\n",
       "        [0.0420],\n",
       "        [0.0412],\n",
       "        [0.0411],\n",
       "        [0.0412],\n",
       "        [0.0407],\n",
       "        [0.0426],\n",
       "        [0.0423],\n",
       "        [0.0428],\n",
       "        [0.0420],\n",
       "        [0.0411],\n",
       "        [0.0425],\n",
       "        [0.0423],\n",
       "        [0.0431],\n",
       "        [0.0412],\n",
       "        [0.0416]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0524],\n",
       "        [0.0387],\n",
       "        [0.0353],\n",
       "        [0.0422],\n",
       "        [0.0349],\n",
       "        [0.0457],\n",
       "        [0.0610],\n",
       "        [0.0091],\n",
       "        [0.0541],\n",
       "        [0.0342],\n",
       "        [0.0396],\n",
       "        [0.0422],\n",
       "        [0.0417],\n",
       "        [0.0384],\n",
       "        [0.0892],\n",
       "        [0.0267],\n",
       "        [0.0303],\n",
       "        [0.0495],\n",
       "        [0.0367],\n",
       "        [0.0362],\n",
       "        [0.0384],\n",
       "        [0.0755],\n",
       "        [0.0424],\n",
       "        [0.0373],\n",
       "        [0.0338],\n",
       "        [0.0537],\n",
       "        [0.0665],\n",
       "        [0.0446],\n",
       "        [0.0216],\n",
       "        [0.0252],\n",
       "        [0.0225],\n",
       "        [0.0325],\n",
       "        [0.0605],\n",
       "        [0.0488],\n",
       "        [0.0245],\n",
       "        [0.0263],\n",
       "        [0.0913],\n",
       "        [0.0402],\n",
       "        [0.0364],\n",
       "        [0.0435],\n",
       "        [0.0320],\n",
       "        [0.0232],\n",
       "        [0.0102],\n",
       "        [0.0568],\n",
       "        [0.0479],\n",
       "        [0.0354],\n",
       "        [0.0305],\n",
       "        [0.0252],\n",
       "        [0.0418],\n",
       "        [0.0280],\n",
       "        [0.0502],\n",
       "        [0.0660],\n",
       "        [0.0418],\n",
       "        [0.0448],\n",
       "        [0.0457],\n",
       "        [0.0913],\n",
       "        [0.0638],\n",
       "        [0.0579],\n",
       "        [0.0440],\n",
       "        [0.0404],\n",
       "        [0.0258],\n",
       "        [0.0782],\n",
       "        [0.0353],\n",
       "        [0.0588],\n",
       "        [0.0482],\n",
       "        [0.0398],\n",
       "        [0.0396],\n",
       "        [0.0152],\n",
       "        [0.0853],\n",
       "        [0.0787],\n",
       "        [0.0575],\n",
       "        [0.0192],\n",
       "        [0.0305],\n",
       "        [0.0365],\n",
       "        [0.0608],\n",
       "        [0.0325],\n",
       "        [0.0913],\n",
       "        [0.0375],\n",
       "        [0.0424],\n",
       "        [0.0239],\n",
       "        [0.0358],\n",
       "        [0.0417],\n",
       "        [0.0524],\n",
       "        [0.0561],\n",
       "        [0.0418],\n",
       "        [0.0400],\n",
       "        [0.0437],\n",
       "        [0.0597],\n",
       "        [0.0444],\n",
       "        [0.0393],\n",
       "        [0.0449],\n",
       "        [0.0155],\n",
       "        [0.0482],\n",
       "        [0.0422],\n",
       "        [0.0274],\n",
       "        [0.0161],\n",
       "        [0.0353],\n",
       "        [0.0437],\n",
       "        [0.0451],\n",
       "        [0.0362],\n",
       "        [0.0435],\n",
       "        [0.0243],\n",
       "        [0.0530],\n",
       "        [0.0495],\n",
       "        [0.0632],\n",
       "        [0.0243],\n",
       "        [0.0285],\n",
       "        [0.0228],\n",
       "        [0.0267],\n",
       "        [0.0201],\n",
       "        [0.0453],\n",
       "        [0.0316],\n",
       "        [0.0148],\n",
       "        [0.0391],\n",
       "        [0.0285],\n",
       "        [0.0426],\n",
       "        [0.0585],\n",
       "        [0.0707],\n",
       "        [0.0550],\n",
       "        [0.0375],\n",
       "        [0.0594],\n",
       "        [0.0773],\n",
       "        [0.0444],\n",
       "        [0.0376],\n",
       "        [0.0402],\n",
       "        [0.0332],\n",
       "        [0.0274],\n",
       "        [0.0115],\n",
       "        [0.0367],\n",
       "        [0.0391],\n",
       "        [0.0519],\n",
       "        [0.0550],\n",
       "        [0.0380],\n",
       "        [0.0420],\n",
       "        [0.0261],\n",
       "        [0.0214],\n",
       "        [0.0681],\n",
       "        [0.0312],\n",
       "        [0.0190],\n",
       "        [0.0420],\n",
       "        [0.0415],\n",
       "        [0.0371],\n",
       "        [0.0396],\n",
       "        [0.0913],\n",
       "        [0.0153],\n",
       "        [0.0343],\n",
       "        [0.0680],\n",
       "        [0.0294],\n",
       "        [0.0301],\n",
       "        [0.0406],\n",
       "        [0.0376],\n",
       "        [0.0247],\n",
       "        [0.0882],\n",
       "        [0.0435],\n",
       "        [0.0415],\n",
       "        [0.0318],\n",
       "        [0.0554],\n",
       "        [0.0658],\n",
       "        [0.0762],\n",
       "        [0.0334],\n",
       "        [0.0402],\n",
       "        [0.0340],\n",
       "        [0.0818],\n",
       "        [0.0217],\n",
       "        [0.0342],\n",
       "        [0.0296],\n",
       "        [0.0402],\n",
       "        [0.0132],\n",
       "        [0.0373],\n",
       "        [0.0252],\n",
       "        [0.0237],\n",
       "        [0.0336],\n",
       "        [0.0422],\n",
       "        [0.0387],\n",
       "        [0.0422],\n",
       "        [0.0429],\n",
       "        [0.0913],\n",
       "        [0.0486],\n",
       "        [0.0406],\n",
       "        [0.0913],\n",
       "        [0.0152],\n",
       "        [0.0426],\n",
       "        [0.0396],\n",
       "        [0.0345],\n",
       "        [0.0336],\n",
       "        [0.0318],\n",
       "        [0.0245],\n",
       "        [0.0221],\n",
       "        [0.0486],\n",
       "        [0.0396],\n",
       "        [0.0519],\n",
       "        [0.0375],\n",
       "        [0.0402],\n",
       "        [0.0254],\n",
       "        [0.0206],\n",
       "        [0.0546],\n",
       "        [0.0486],\n",
       "        [0.0192],\n",
       "        [0.0424],\n",
       "        [0.0446],\n",
       "        [0.0840],\n",
       "        [0.0400],\n",
       "        [0.0137],\n",
       "        [0.0661],\n",
       "        [0.0804],\n",
       "        [0.0325],\n",
       "        [0.0502],\n",
       "        [0.0687],\n",
       "        [0.0258],\n",
       "        [0.0513],\n",
       "        [0.0186],\n",
       "        [0.0349],\n",
       "        [0.0800],\n",
       "        [0.0510],\n",
       "        [0.0457],\n",
       "        [0.0292],\n",
       "        [0.0303],\n",
       "        [0.0241],\n",
       "        [0.0913],\n",
       "        [0.0406],\n",
       "        [0.0601],\n",
       "        [0.0278],\n",
       "        [0.0270],\n",
       "        [0.0252],\n",
       "        [0.0444],\n",
       "        [0.0617],\n",
       "        [0.0407],\n",
       "        [0.0913],\n",
       "        [0.0174],\n",
       "        [0.0243],\n",
       "        [0.0406],\n",
       "        [0.0331],\n",
       "        [0.0329],\n",
       "        [0.0457],\n",
       "        [0.0301],\n",
       "        [0.0420],\n",
       "        [0.0367],\n",
       "        [0.0603],\n",
       "        [0.0453],\n",
       "        [0.0332],\n",
       "        [0.0239],\n",
       "        [0.0638],\n",
       "        [0.0186],\n",
       "        [0.0364],\n",
       "        [0.0510],\n",
       "        [0.0426],\n",
       "        [0.0641],\n",
       "        [0.0234],\n",
       "        [0.0402],\n",
       "        [0.0338],\n",
       "        [0.0459],\n",
       "        [0.0411],\n",
       "        [0.0409],\n",
       "        [0.0522],\n",
       "        [0.0356],\n",
       "        [0.0453],\n",
       "        [0.0448],\n",
       "        [0.0391],\n",
       "        [0.0605],\n",
       "        [0.0418],\n",
       "        [0.0378],\n",
       "        [0.0440],\n",
       "        [0.0913],\n",
       "        [0.0451],\n",
       "        [0.0524],\n",
       "        [0.0132],\n",
       "        [0.0676],\n",
       "        [0.0371],\n",
       "        [0.0550],\n",
       "        [0.0356],\n",
       "        [0.0427],\n",
       "        [0.0210],\n",
       "        [0.0395],\n",
       "        [0.0272],\n",
       "        [0.0278],\n",
       "        [0.0354],\n",
       "        [0.0153],\n",
       "        [0.0512],\n",
       "        [0.0413],\n",
       "        [0.0247],\n",
       "        [0.0265],\n",
       "        [0.0566],\n",
       "        [0.0199],\n",
       "        [0.0400],\n",
       "        [0.0402],\n",
       "        [0.0347],\n",
       "        [0.0391],\n",
       "        [0.0457],\n",
       "        [0.0320],\n",
       "        [0.0667],\n",
       "        [0.0367],\n",
       "        [0.0373],\n",
       "        [0.0296],\n",
       "        [0.0431],\n",
       "        [0.0135],\n",
       "        [0.0643],\n",
       "        [0.0913],\n",
       "        [0.0353],\n",
       "        [0.0387],\n",
       "        [0.0285],\n",
       "        [0.0610],\n",
       "        [0.0349],\n",
       "        [0.0384],\n",
       "        [0.0433],\n",
       "        [0.0345],\n",
       "        [0.0307],\n",
       "        [0.0360],\n",
       "        [0.0323],\n",
       "        [0.0413],\n",
       "        [0.0216],\n",
       "        [0.0638],\n",
       "        [0.0376],\n",
       "        [0.0369],\n",
       "        [0.0585],\n",
       "        [0.0407],\n",
       "        [0.0426],\n",
       "        [0.0263],\n",
       "        [0.0570],\n",
       "        [0.0438],\n",
       "        [0.0541],\n",
       "        [0.0358],\n",
       "        [0.0395],\n",
       "        [0.0365],\n",
       "        [0.0493],\n",
       "        [0.0607],\n",
       "        [0.0281],\n",
       "        [0.0557],\n",
       "        [0.0132],\n",
       "        [0.0437],\n",
       "        [0.0298],\n",
       "        [0.0437],\n",
       "        [0.0913],\n",
       "        [0.0417],\n",
       "        [0.0281],\n",
       "        [0.0351],\n",
       "        [0.0358],\n",
       "        [0.0413],\n",
       "        [0.0607],\n",
       "        [0.0913],\n",
       "        [0.0406],\n",
       "        [0.0272],\n",
       "        [0.0362],\n",
       "        [0.0433],\n",
       "        [0.0347],\n",
       "        [0.0371],\n",
       "        [0.0217],\n",
       "        [0.0248],\n",
       "        [0.0544],\n",
       "        [0.0396],\n",
       "        [0.0356],\n",
       "        [0.0385],\n",
       "        [0.0448],\n",
       "        [0.0245],\n",
       "        [0.0340]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
